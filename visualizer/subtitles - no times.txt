This is an explanation video for
an Algorithm to play the board
game "Codenames", written
by Michael and Asaf Kali.
Part 1: The board game Codenames
Let's first describe the game.
In the game, two groups are competing eachother
- The blue team and the red team
In each group there are two types
of players: The Spymaster, and the
field operatives, which are often played
by multiple people
On the board there are
25 cards, each one with a
word witten on in.
Some cards represent blue agents,
and some represent red agents.
one represents a black Assassin, and the
others represent innocent gray Bystanders.
but only the two Spymasters
hold the map that tells which
card is assigned to which team.
The goal of the Spymasters is to
have all the cards of their color exposed
to do so, in each turn the Spymaster
chooses some of the cards of his color
to hint about.
He then hint about them with a
single word, that somehow relates
to each of them, and adds the
number of cards he is hinting about
Then, the field operatives guess which
cards did the Spymaster hint about.
with each guess, The true color
of the card is being revealed.
Even when the Field
Operators guess a card from the
correct color, the Spymaster
may not give away if that
was the card he hinted about or not.
The Spymaster can try to
hint at many cards at once, but
if the Field Operators accidentally
choose a card from the
opponent’s color or a
Bystander's gray card,
they loose their turn
If they hit the black Assassin’s
card - The team immediately looses.

On the screen, the blue
guesser mistakes "costume" as
a hint for "ninja", and the
blue team looses since
"ninja" is the black Assassin.
Part 2: The Word2Vec Model
The Algorithm in discussion
uses a pre-trained Word2Vec model
for it's linguistic knowledge.
The Word2Vec model uses a big text
corpus such as Wikipedia or news sites
to assign each word in the
vocabulary with an n-dimensional vector
The vectors of the various words are
designed such that words that tend to
appear in the same context will
have small angle between them, while
distant, unrelated words will
have a larger angle between them.
Part 3: The Codenames Algorithm
Now we will describe
the algorithm itself
To see the problem from
the algorithm's perspective,
We will visualize the cards
words as 3 dimensional
unit vectors in a 3-d space.
In each turn, the first task
of the hinter is to find a
proper subset of words
(usually two to four words)
on which to hint
Two methods of clustering
where implemented.
In the first clustering method, the
words are considered as nodes in a graph
with edges weights correlated
to their cosine similarity.
This graph is divided into communities
using the Louvain SNA algorithm, and each
community is taken as an optional
cluster of words to hint about in the next step.
The cluster are represented here
as groups of connected vectors.
A second, "greedy" method, simply
iterates over all combinations of words to
choose the best one.
The second task of the hinter
is to choose a hinting word for
each of the proposed clusters.
In order to find a hinting word for a cluster,
the Spymaster (hinter) generates a "centroid"
vector for the cluster, to
search real words near by.
An initial "centroid" is proposed as the
Center of Mass of the cluster's vectors
Ideally, the centroid would be close to all
the cluster's words and far from words of
other colors. (where "close" and
"far") are considered in the angle metric.
To optimize the centroid, the nearby words in
the board (from  all colors) are considered
as a physical system, where every
vector from the color of the hinter is an
attractor, and every word
from other colors is a repeller.
The centroid is then being pushed
and pulled by the words of the board
until converging to a point where it
is both far away from bad words, and
close the cluster's words.
The attraction force acts like a
spring, where if the centroid is too far,
the spring can be "torn" apart and is no
longer considered as part of the cluster.
This is done in order to allow
outliers in the cluster to be throwen away.
After convergence, all there
needs to be done is to pick up a word
near-by the optimized
cluster's centroid.
The top n words with the lowest
cosine distance are examined
and the best one is
chosen as the cluster's hint
The best hint from all clusters
is picked and being hinted to the
Field Operators (the guessers).
Part 4: Examples
Here is an example of a well
hinted word by the algorithm
On the X-axis, lay the unrevealed
cards, when the Spymaster hinted:
"redevelopment, 2 cards".
On the Y-axis, you can see the
cosine distance between the hinted
word "redevelopment" and the unrevealed cards.
as can be seen when the Field
Operators search for the closest words
to "redevelopment", "park" and "skyscrapper"
are significantly closer then the
other cards, and thus those
will be his two guesses.
Here is another example
of a less successful hint
As can be seen, the word
"frog" is close to
the hint "rhino", almost as
the desired word "parrot"
This might confuse the
guesser, and thus this hint will
not be picked.
Thanks for wathing!
